{
    "dataset_reader": {
      "lazy": false,
      "type": "semisupervised_text_classification_json",
      "tokenizer": {
          "word_splitter": "spacy",
          "word_filter": {
              "type": "regex_and_stopwords",
              "patterns": [
                          // "\\w{1,3}\\b", // tokens of length <= 3
                          //  "\\w*\\d+\\w*", // words that contain digits,
                           "\\w*[^\\P{P}\\-]+\\w*" // punctuation
                          ],
                          "stopword_file": "vae/tests/fixtures/stopwords/snowball_stopwords.txt"
             }
      },
      "token_indexers": {
          "tokens": {
            "type": "single_id",
            "namespace": "vae",
            "lowercase_tokens": true
        }
      },
      "sequence_length": 400
  },
  "train_data_path": "vae/tests/fixtures/imdb/train.jsonl",
  "validation_data_path": "vae/tests/fixtures/imdb/test.jsonl",
  "vocabulary":{
    "type": "bg_dumper",
    "max_vocab_size": {
      "vae": 2000,
      "classifier": 10000
    }
  },
    "model": {
      "type": "nvdm",
      "update_background_freq": true,
      "kl_weight_annealing": "constant",
      "reference_counts": "vae/tests/fixtures/reference_corpus/dev.npz",
      "reference_vocabulary": "vae/tests/fixtures/reference_corpus/dev.vocab.json",
      "bow_embedder": {
          "type": "bag_of_word_counts",
          "vocab_namespace": "vae",
          "ignore_oov": true
      },
      "vae": {
        "type": "logistic_normal",
        "encoder": {
          "input_dim": 307,
          "num_layers": 2,
          "hidden_dims": [1000, 300],
          "activations": ["relu", "relu"]
        },
        "mean_projection": {
          "input_dim": 300,
          "num_layers": 1,
          "hidden_dims": [10],
          "activations": ["linear"]
        },
        "log_variance_projection": {
          "input_dim": 300,
          "num_layers": 1,
          "hidden_dims": [10],
          "activations": ["linear"]
        },
        "decoder": {
          "input_dim": 10,
          "num_layers": 1,
          "hidden_dims": [307],
          "activations": ["tanh"]
        },
        "apply_batchnorm": true,
        "z_dropout": 0.2
      }
    },
    "iterator": {
      "type": "basic",
      "batch_size": 100,
      "track_epoch": true
    },
    "trainer": {
      "validation_metric": "-nll",
      "num_epochs": 5,
      "patience": 5,
      "cuda_device": -1,
      "optimizer": {
        "type": "adam",
        "lr": 0.001,
        "weight_decay": 0.001
      }
    }
  }
    
  