{
    "dataset_reader":{
        "type": "sst",
        "use_subtrees": false,
        "granularity": "2-class"
    },
    "validation_dataset_reader":{
        "type": "sst",
        "use_subtrees": false,
        "granularity": "2-class"
    },
    "vocabulary":{
    "directory_path": "/home/ubuntu/data/sst/vocabulary/"
},
"datasets_for_vocab_creation": ["train"],
"train_data_path": "https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/train.txt",
"validation_data_path": "https://s3-us-west-2.amazonaws.com/allennlp/datasets/sst/dev.txt",
    "model": {
        "type": "seq2seq_classifier",
        "text_field_embedder": {
            "token_embedders": {
                "tokens": {
                    "type": "embedding",
                    "embedding_dim": 300,
                    "pretrained_file": "/home/ubuntu/data/word-vecs",
                    "trainable": true,
                    "vocab_namespace": "full",
                },
            },
        },
        "pretrained_vae_file": "/home/ubuntu/vae/model_logs/nvrnn/nvrnn_lstm_lstm_ln_recon_theta/model.tar.gz",
        "freeze_pretrained_weights": true,
        "use_dummy_theta": false,
        "use_theta": true,
        "use_decoder_weights": false,
        "use_encoder_weights": true,
        "use_embedder": false,
        "dropout": 0.2,
        "encoder": {
           "type": "lstm",
           "num_layers": 2,
           "bidirectional": true,
	       "input_size": 300,
           "hidden_size": 256, 
        },
        "initializer": [
            [".*linear_layers.*weight", {"type": "xavier_uniform"}],
            [".*linear_layers.*bias", {"type": "zero"}],
            [".*weight_ih.*", {"type": "xavier_uniform"}],
            [".*weight_hh.*", {"type": "orthogonal"}],
            [".*bias_ih.*", {"type": "zero"}],
            [".*bias_hh.*", {"type": "lstm_hidden_bias"}]
        ]
    },
    "iterator": {
        "type": "bucket",
        "sorting_keys": [["tokens", "num_tokens"]],
        "batch_size": 8
    },
    "trainer": {
        "optimizer": {
            "type": "adam",
            "lr": 0.001
        },
        "validation_metric": "+accuracy",
        "num_serialized_models_to_keep": 2,
        "num_epochs": 75,
        "grad_norm": 10.0,
        "patience": 20,
        "cuda_device": 0,
        "learning_rate_scheduler": {
            "type": "reduce_on_plateau",
            "factor": 0.5,
            "mode": "max",
            "patience": 0
        }
    }
}

